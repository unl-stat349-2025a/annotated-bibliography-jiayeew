% bib file

% Start with your annual review article





% Below that, add bibtex for your sources
@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  year = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-02-03},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/Users/jiayeewong/Zotero/storage/A6T8ITAV/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf}
}

@article{grigorescuSurveyDeepLearning2020,
  title = {A Survey of Deep Learning Techniques for Autonomous Driving},
  author = {Grigorescu, Sorin and Trasnea, Bogdan and Cocias, Tiberiu and Macesanu, Gigel},
  date = {2020},
  journaltitle = {Journal of Field Robotics},
  volume = {37},
  number = {3},
  pages = {362--386},
  issn = {1556-4967},
  doi = {10.1002/rob.21918},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21918},
  urldate = {2025-02-08},
  abstract = {The last decade witnessed increasingly rapid progress in self-driving vehicle technology, mainly backed up by advances in the area of deep learning and artificial intelligence (AI). The objective of this paper is to survey the current state-of-the-art on deep learning technologies used in autonomous driving. We start by presenting AI-based self-driving architectures, convolutional and recurrent neural networks, as well as the deep reinforcement learning paradigm. These methodologies form a base for the surveyed driving scene perception, path planning, behavior arbitration, and motion control algorithms. We investigate both the modular perception-planning-action pipeline, where each module is built using deep learning methods, as well as End2End systems, which directly map sensory information to steering commands. Additionally, we tackle current challenges encountered in designing AI architectures for autonomous driving, such as their safety, training data sources, and computational hardware. The comparison presented in this survey helps gain insight into the strengths and limitations of deep learning and AI approaches for autonomous driving and assist with design choices.},
  langid = {english},
  keywords = {AI for self-driving vehicles,artificial intelligence,autonomous driving,deep learning for autonomous driving},
  file = {/Users/jiayeewong/Zotero/storage/PDQ35QHD/Grigorescu et al. - 2020 - A survey of deep learning techniques for autonomous driving.pdf;/Users/jiayeewong/Zotero/storage/FXVS9MGM/rob.html}
}

@article{nalisnickBriefTourDeep2023,
  title = {A {{Brief Tour}} of {{Deep Learning}} from a {{Statistical Perspective}}},
  author = {Nalisnick, Eric and Smyth, Padhraic and Tran, Dustin},
  date = {2023-03-09},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {10},
  pages = {219--246},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-032921-013738},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-032921-013738},
  urldate = {2025-02-03},
  abstract = {We expose the statistical foundations of deep learning with the goal of facilitating conversation between the deep learning and statistics communities. We highlight core themes at the intersection; summarize key neural models, such as feedforward neural networks, sequential neural networks, and neural latent variable models; and link these ideas to their roots in probability and statistics. We also highlight research directions in deep learning where there are opportunities for statistical contributions.},
  issue = {Volume 10, 2023},
  langid = {english},
  file = {/Users/jiayeewong/Zotero/storage/2TUX3RZK/Nalisnick et al. - 2023 - A Brief Tour of Deep Learning from a Statistical Perspective.pdf;/Users/jiayeewong/Zotero/storage/G9EKGHWJ/annurev-statistics-032921-013738.html}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@article{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
